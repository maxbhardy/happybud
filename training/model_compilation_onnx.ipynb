{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compilation du modèle avec ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Classes et fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "class ReshapeToBatchChannelFirst(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReshapeToBatchChannelFirst, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Ensure the input is of shape (224, 224, 3)\n",
    "        #assert x.dim() == 3 and x.shape[-1] == 3, \"Input must be (224, 224, 3)\"\n",
    "        \n",
    "        # Permute dimensions from (H, W, C) to (C, H, W)\n",
    "        x = x.permute(2, 0, 1)\n",
    "        \n",
    "        # Add a batch dimension at the beginning: (1, C, H, W)\n",
    "        x = x.unsqueeze(0)\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "x = torch.rand(224, 224, 3)  # Example input\n",
    "layer = ReshapeToBatchChannelFirst()\n",
    "output = layer(x)\n",
    "print(output.shape)  # Expected: torch.Size([1, 3, 224, 224])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-2.1140]],\n",
      "\n",
      "         [[-2.0340]],\n",
      "\n",
      "         [[-1.7985]]]])\n"
     ]
    }
   ],
   "source": [
    "class FixedNormLayer(torch.nn.Module):\n",
    "    def __init__(self, scale=torch.tensor([1 / 256]), mean=torch.tensor([0.485, 0.456, 0.406]), std=torch.tensor([0.229, 0.224, 0.225])):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            mean (torch.Tensor): Precomputed mean for normalization.\n",
    "            std (torch.Tensor): Precomputed standard deviation for normalization.\n",
    "        \"\"\"\n",
    "        super(FixedNormLayer, self).__init__()\n",
    "        self.register_buffer(\"mean\", mean[:, None, None])\n",
    "        self.register_buffer(\"std\", std[:, None, None])\n",
    "        self.register_buffer(\"scale\", scale)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return (self.scale * x - self.mean) / self.std\n",
    "\n",
    "# Example usage\n",
    "layer = FixedNormLayer()\n",
    "\n",
    "# Test with a sample input\n",
    "x = torch.rand(1, 3, 1, 1)  # Example input\n",
    "output = layer(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceModel(torch.nn.Module):\n",
    "    def __init__(self, model, scale=torch.tensor([1 / 256]), mean=torch.tensor([0.485, 0.456, 0.406]), std=torch.tensor([0.229, 0.224, 0.225])):\n",
    "        super(InferenceModel, self).__init__()\n",
    "        self.preprocess = torch.nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\"reshape\", ReshapeToBatchChannelFirst()),\n",
    "                    (\"normalize\", FixedNormLayer(scale, mean, std)),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        self.model = model  # The main model\n",
    "        self.postprocess = torch.nn.Softmax(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.preprocess(x)  # Apply reshaping and normalization\n",
    "        x = self.model(x)  # Pass to the main model\n",
    "        return self.postprocess(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceModelEncoder(torch.nn.Module):\n",
    "    def __init__(self, model, scale=torch.tensor([1 / 256]), mean=torch.tensor([0.485, 0.456, 0.406]), std=torch.tensor([0.229, 0.224, 0.225])):\n",
    "        super(InferenceModelEncoder, self).__init__()\n",
    "        self.preprocess = torch.nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\"reshape\", ReshapeToBatchChannelFirst()),\n",
    "                    (\"normalize\", FixedNormLayer(scale, mean, std)),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        self.model = model  # The main model\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.preprocess(x)  # Apply reshaping and normalization\n",
    "        x = self.model(x)  # Pass to the main model\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceModelDecoder(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(InferenceModelDecoder, self).__init__()\n",
    "        self.model = model  # The main model last layer\n",
    "        self.postprocess = torch.nn.Softmax(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)  # Pass to the main model\n",
    "        return self.postprocess(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from onnxruntime.tools import convert_onnx_models_to_ort as convert_onnx\n",
    "\n",
    "def export_to_onnx(model, model_input, model_name, path=\".\", target_platform=\"arm\"):\n",
    "    path = pathlib.Path(path)\n",
    "\n",
    "    # Export to ONNX format\n",
    "    onnx_program = torch.onnx.export(model, model_input, dynamo=True)\n",
    "    onnx_program.save((path / model_name).with_suffix(\".onnx\"))\n",
    "\n",
    "    # Export to ORT format for mobile\n",
    "    convert_onnx.convert_onnx_models_to_ort(\n",
    "        (path / model_name).with_suffix(\".onnx\"),\n",
    "        output_dir=pathlib.Path(\"models\"),\n",
    "        optimization_styles=[convert_onnx.OptimizationStyle.Fixed],\n",
    "        target_platform=target_platform,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import numpy as np\n",
    "\n",
    "def single_image_pipeline(image_path, dtype=\"float32\"):\n",
    "    # Load image into numpy float array\n",
    "    image = np.array(\n",
    "        PIL.Image.open(image_path).convert(\"RGB\").resize((224, 224)), dtype=dtype\n",
    "    )\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Modèle de tomates (2025-02-28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modification du modèle pour avoir le bon nombre de sortie dans la dernière couche et\n",
    "pour calculer le softmax sur les sorties du modèle pour avoir directement les probabilités."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained ViT\n",
    "num_labels = 11  # Get number of labels (e.g., 8)\n",
    "\n",
    "model = torchvision.models.vit_b_16(weights=\"IMAGENET1K_V1\")  # Load a pretrained model\n",
    "model.heads.head = torch.nn.Linear(model.heads.head.in_features, num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"models/tomato_model_2025_02_28_v2.pt\",\n",
    "        map_location=device,\n",
    "        weights_only=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0214, 0.6054, 0.2210, 0.0181, 0.0034, 0.0022, 0.0020, 0.0814, 0.0186,\n",
       "         0.0066, 0.0199]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create inference model\n",
    "inference_model = InferenceModel(model)\n",
    "inference_model.eval()\n",
    "\n",
    "model_input = torch.randn(224, 224, 3)\n",
    "inference_model(model_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exportation du modèle, en incluant un tenseur aléatoire pour fournir la bonne taille de\n",
    "tenseur en entrée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxime/.venvs/ai/lib64/python3.11/site-packages/onnxscript/converter.py:823: FutureWarning: 'onnxscript.values.Op.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.\n",
      "  param_schemas = callee.param_schemas()\n",
      "/home/maxime/.venvs/ai/lib64/python3.11/site-packages/onnxscript/converter.py:823: FutureWarning: 'onnxscript.values.OnnxFunction.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.\n",
      "  param_schemas = callee.param_schemas()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `InferenceModel([...]` with `torch.export.export`...\n",
      "[torch.onnx] Obtain model graph for `InferenceModel([...]` with `torch.export.export`... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "Converting models with optimization style 'Fixed' and level 'all'\n",
      "Converting optimized ONNX model /home/maxime/Documents/Code/happybud/training/models/tomato_model_2025_02_28_v2.onnx to ORT format model /home/maxime/Documents/Code/happybud/training/models/tomato_model_2025_02_28_v2.ort\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2025-03-24 11:39:21.050759422 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_scaled_dot_product_flash_attention_for_cpu_11__1' source:{1,197,32} target:{1,12,197}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:39:21.051144272 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_scaled_dot_product_flash_attention_for_cpu_10__1' source:{1,197,32} target:{1,12,197}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:39:21.051419147 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_scaled_dot_product_flash_attention_for_cpu_9__1' source:{1,197,32} target:{1,12,197}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:39:21.051678545 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_scaled_dot_product_flash_attention_for_cpu_8__1' source:{1,197,32} target:{1,12,197}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:39:21.051946730 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_scaled_dot_product_flash_attention_for_cpu_7__1' source:{1,197,32} target:{1,12,197}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:39:21.052284609 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_scaled_dot_product_flash_attention_for_cpu_6__1' source:{1,197,32} target:{1,12,197}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:39:21.052762729 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_scaled_dot_product_flash_attention_for_cpu_5__1' source:{1,197,32} target:{1,12,197}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:39:21.053243901 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_scaled_dot_product_flash_attention_for_cpu_4__1' source:{1,197,32} target:{1,12,197}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:39:21.053637011 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_scaled_dot_product_flash_attention_for_cpu_3__1' source:{1,197,32} target:{1,12,197}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:39:21.053919680 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_scaled_dot_product_flash_attention_for_cpu_2__1' source:{1,197,32} target:{1,12,197}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:39:21.054201677 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_scaled_dot_product_flash_attention_for_cpu_1__1' source:{1,197,32} target:{1,12,197}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:39:21.054505910 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_scaled_dot_product_flash_attention_for_cpu__1' source:{1,197,32} target:{1,12,197}. Falling back to lenient merge.\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 1/1 models successfully.\n",
      "Generating config file from ORT format models with optimization style 'Fixed' and level 'all'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 11:39:24,795 ort_format_model.utils [INFO] - Created config in /home/maxime/Documents/Code/happybud/training/models/tomato_model_2025_02_28_v2.required_operators.config\n"
     ]
    }
   ],
   "source": [
    "export_to_onnx(inference_model, model_input, \"tomato_model_2025_02_28_v2\", \"models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation de l'exécution du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(\n",
    "    \"models/tomato_model_2025_02_28_v2.ort\", providers=[\"CPUExecutionProvider\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1.4499956e-06, 9.2473856e-06, 2.0949049e-06, 8.7807521e-06,\n",
       "         1.5942251e-05, 7.3268457e-06, 1.2185792e-06, 9.3832959e-06,\n",
       "         7.4934615e-06, 1.7394861e-05, 9.9991953e-01]], dtype=float32)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exécution du modèle avec ONNX\n",
    "onnx_input = single_image_pipeline(\n",
    "    \"dataset/tomato/88614302-e6d2-4327-a4fb-a3db9c9ea72e___YLCV_NREC_2861.JPG\"\n",
    ")\n",
    "\n",
    "onnxruntime_outputs = ort_session.run(None, {\"x\": onnx_input})\n",
    "onnxruntime_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4500e-06, 9.2474e-06, 2.0949e-06, 8.7807e-06, 1.5942e-05, 7.3268e-06,\n",
       "         1.2186e-06, 9.3833e-06, 7.4934e-06, 1.7395e-05, 9.9992e-01]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exécution du modèle avec pytorch\n",
    "torch_input = torch.tensor(onnx_input)\n",
    "\n",
    "inference_model(torch_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Tomates - Séparation de l'encodeur et du décodeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained ViT\n",
    "num_labels = 11  # Get number of labels (e.g., 8)\n",
    "\n",
    "model = torchvision.models.vit_b_16(weights=\"IMAGENET1K_V1\")  # Load a pretrained model\n",
    "model.heads.head = torch.nn.Linear(model.heads.head.in_features, num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"models/tomato_model_2025_02_28_v2.pt\",\n",
    "        map_location=device,\n",
    "        weights_only=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0183, -0.0336, -0.0224,  ..., -0.0234, -0.0337,  0.0222],\n",
       "        [ 0.0133,  0.0046,  0.0376,  ..., -0.0338, -0.0195, -0.0039],\n",
       "        [ 0.0117,  0.0335, -0.0085,  ...,  0.0160, -0.0332, -0.0282],\n",
       "        ...,\n",
       "        [ 0.0254, -0.0356, -0.0124,  ...,  0.0298,  0.0253, -0.0077],\n",
       "        [ 0.0218,  0.0312, -0.0024,  ..., -0.0325,  0.0179,  0.0299],\n",
       "        [-0.0239, -0.0136,  0.0181,  ...,  0.0369, -0.0023, -0.0013]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract last layer\n",
    "last_layer = torch.nn.Linear(model.heads.head.in_features, num_labels)\n",
    "last_layer.weight = model.heads.head.weight\n",
    "last_layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove last layer from model\n",
    "model.heads.head = torch.nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define encoder and decoder inference models\n",
    "inference_model_encoder = InferenceModelEncoder(model)\n",
    "inference_model_decoder = InferenceModelDecoder(last_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0228, 0.5928, 0.2303, 0.0178, 0.0034, 0.0024, 0.0021, 0.0838, 0.0181,\n",
       "         0.0065, 0.0201]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test inference model encoder and decoder\n",
    "torch_input = torch.randn(224, 224, 3)\n",
    "\n",
    "encoded = inference_model_encoder(torch_input)\n",
    "decoded = inference_model_decoder(encoded)\n",
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `InferenceModelEncoder([...]` with `torch.export.export`...\n",
      "[torch.onnx] Obtain model graph for `InferenceModelEncoder([...]` with `torch.export.export`... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "Converting models with optimization style 'Fixed' and level 'all'\n",
      "Converting optimized ONNX model /home/maxime/Documents/Code/happybud/training/models/tomato_model_2025_02_28_v2_encoder.onnx to ORT format model /home/maxime/Documents/Code/happybud/training/models/tomato_model_2025_02_28_v2_encoder.ort\n",
      "Converted 1/1 models successfully.\n",
      "Generating config file from ORT format models with optimization style 'Fixed' and level 'all'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2025-03-24 11:54:14.855933978 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_scaled_dot_product_flash_attention_for_cpu_11__1' source:{1,197,32} target:{1,12,197}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:54:14.856286110 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_scaled_dot_product_flash_attention_for_cpu_10__1' source:{1,197,32} target:{1,12,197}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:54:14.856528573 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_scaled_dot_product_flash_attention_for_cpu_9__1' source:{1,197,32} target:{1,12,197}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:54:14.856755973 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_scaled_dot_product_flash_attention_for_cpu_8__1' source:{1,197,32} target:{1,12,197}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:54:14.856990589 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_scaled_dot_product_flash_attention_for_cpu_7__1' source:{1,197,32} target:{1,12,197}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:54:14.857213296 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_scaled_dot_product_flash_attention_for_cpu_6__1' source:{1,197,32} target:{1,12,197}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:54:14.857474236 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_scaled_dot_product_flash_attention_for_cpu_5__1' source:{1,197,32} target:{1,12,197}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:54:14.857695419 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_scaled_dot_product_flash_attention_for_cpu_4__1' source:{1,197,32} target:{1,12,197}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:54:14.857915580 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_scaled_dot_product_flash_attention_for_cpu_3__1' source:{1,197,32} target:{1,12,197}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:54:14.858130094 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_scaled_dot_product_flash_attention_for_cpu_2__1' source:{1,197,32} target:{1,12,197}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:54:14.858377202 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_scaled_dot_product_flash_attention_for_cpu_1__1' source:{1,197,32} target:{1,12,197}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:54:14.858592215 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_scaled_dot_product_flash_attention_for_cpu__1' source:{1,197,32} target:{1,12,197}. Falling back to lenient merge.\u001b[m\n",
      "2025-03-24 11:54:17,519 ort_format_model.utils [INFO] - Created config in /home/maxime/Documents/Code/happybud/training/models/tomato_model_2025_02_28_v2_encoder.required_operators.config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `InferenceModelDecoder([...]` with `torch.export.export`...\n",
      "[torch.onnx] Obtain model graph for `InferenceModelDecoder([...]` with `torch.export.export`... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 11:54:18,157 ort_format_model.utils [INFO] - Created config in /home/maxime/Documents/Code/happybud/training/models/tomato_model_2025_02_28_v2_decoder.required_operators.config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "Converting models with optimization style 'Fixed' and level 'all'\n",
      "Converting optimized ONNX model /home/maxime/Documents/Code/happybud/training/models/tomato_model_2025_02_28_v2_decoder.onnx to ORT format model /home/maxime/Documents/Code/happybud/training/models/tomato_model_2025_02_28_v2_decoder.ort\n",
      "Converted 1/1 models successfully.\n",
      "Generating config file from ORT format models with optimization style 'Fixed' and level 'all'\n"
     ]
    }
   ],
   "source": [
    "# Export to ONNX\n",
    "export_to_onnx(inference_model_encoder, torch_input, \"tomato_model_2025_02_28_v2_encoder\", \"models\")\n",
    "export_to_onnx(inference_model_decoder, encoded, \"tomato_model_2025_02_28_v2_decoder\", \"models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation de l'exécution du modèle avec ONNX runtime (encoder decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "\n",
    "ort_session_encoder = onnxruntime.InferenceSession(\n",
    "    \"models/tomato_model_2025_02_28_v2_encoder.ort\", providers=[\"CPUExecutionProvider\"]\n",
    ")\n",
    "\n",
    "ort_session_decoder = onnxruntime.InferenceSession(\n",
    "    \"models/tomato_model_2025_02_28_v2_decoder.ort\", providers=[\"CPUExecutionProvider\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.07714486e-01,  3.03961895e-02,  8.70138347e-01,\n",
       "        -8.18296134e-01, -2.94012278e-01,  3.38016897e-01,\n",
       "        -1.66627228e-01,  2.50272691e-01,  9.25460935e-01,\n",
       "        -1.28882408e-01, -4.14819241e-01,  5.26395202e-01,\n",
       "         3.60564172e-01, -9.18535769e-01,  1.99042767e-01,\n",
       "         3.08376225e-03,  4.41153377e-01, -9.58642066e-01,\n",
       "        -7.41269588e-02, -6.60064757e-01, -8.72934103e-01,\n",
       "         1.00470901e+00, -4.35145259e-01,  5.68119287e-01,\n",
       "         4.17836487e-01, -1.07043183e+00,  3.48927267e-02,\n",
       "         8.65398228e-01, -1.04337978e+00,  7.23374665e-01,\n",
       "         1.12749267e+00, -8.93599689e-02, -9.41086590e-01,\n",
       "        -1.05196118e+00,  7.97558486e-01, -3.89004469e-01,\n",
       "         2.09360659e-01,  2.86927879e-01,  8.63989294e-01,\n",
       "        -1.43604070e-01, -1.26661167e-01, -1.56991780e-01,\n",
       "        -6.36127830e-01, -1.38813198e-01,  4.89442497e-01,\n",
       "         6.29252195e-01,  7.34239221e-01, -7.45796412e-02,\n",
       "        -1.43365824e+00,  4.67331916e-01, -7.53821850e-01,\n",
       "        -6.70162976e-01,  1.02852225e+00, -1.13496757e+00,\n",
       "         3.24766636e-01,  5.53461850e-01,  1.58791590e+00,\n",
       "         6.77139610e-02, -7.94435501e-01,  2.36945495e-01,\n",
       "         9.71626043e-01, -3.53950053e-01, -1.43276989e-01,\n",
       "        -1.07344794e+00,  3.75737734e-02, -6.38013661e-01,\n",
       "         5.08531153e-01, -1.30250800e+00,  5.64293146e-01,\n",
       "        -3.29165250e-01, -6.49384439e-01,  1.54316163e+00,\n",
       "         3.48707974e-01, -7.94233158e-02,  4.08519477e-01,\n",
       "        -2.68674940e-01, -1.31432986e+00,  3.99362653e-01,\n",
       "        -1.00661027e+00, -2.06877664e-01,  2.02734202e-01,\n",
       "         1.22810102e+00,  4.49862987e-01, -3.54892612e-01,\n",
       "        -4.02746767e-01,  6.99638963e-01,  6.65886998e-01,\n",
       "        -4.94200557e-01, -1.09640336e+00,  1.33213711e+00,\n",
       "         2.78999239e-01,  6.50179207e-01, -6.25403702e-01,\n",
       "        -1.84427574e-02, -1.80607164e+00,  1.07137859e+00,\n",
       "        -1.89597942e-02,  2.83528000e-01,  1.22255862e-01,\n",
       "         1.19170792e-01,  1.71038136e-01,  1.58198804e-01,\n",
       "         2.48566955e-01,  7.70667791e-01,  6.75796270e-02,\n",
       "        -3.50712091e-01,  4.85951871e-01,  1.08819850e-01,\n",
       "        -2.18748957e-01,  4.62637097e-01, -8.82991970e-01,\n",
       "        -1.66640162e-01, -1.81976068e+00, -1.62447304e-01,\n",
       "        -9.63447750e-01, -6.37868285e-01,  1.07023871e+00,\n",
       "        -3.25960517e-01,  4.26908433e-01,  5.15605032e-01,\n",
       "         8.64998579e-01, -8.61770988e-01, -1.68419987e-01,\n",
       "        -2.48389423e-01, -6.14036202e-01,  2.37330884e-01,\n",
       "         2.24579975e-01, -1.87513798e-01, -7.15805769e-01,\n",
       "        -6.08557165e-01,  4.48583961e-01, -9.27658856e-01,\n",
       "        -4.21912670e-02, -1.14979275e-01,  7.19217002e-01,\n",
       "         6.14950240e-01, -1.11231017e+00,  4.64574218e-01,\n",
       "         1.06398022e+00, -4.64582115e-01, -6.63705468e-01,\n",
       "         4.91339087e-01, -8.35815132e-01,  7.40572810e-01,\n",
       "         8.47434223e-01, -6.33902431e-01,  1.62588865e-01,\n",
       "         1.45595193e-01,  9.88190770e-01, -1.45997012e+00,\n",
       "         2.75481910e-01,  2.14052245e-01, -1.74396276e+00,\n",
       "         7.17804253e-01,  8.34677100e-01, -7.64780998e-01,\n",
       "         7.11582124e-01, -4.16133195e-01, -1.02517962e+00,\n",
       "        -2.71902412e-01, -1.35810971e+00, -1.22455513e+00,\n",
       "         6.12920284e-01, -1.19225323e-01,  1.33340371e+00,\n",
       "         1.87850988e+00, -1.40904784e-01, -7.69195616e-01,\n",
       "         7.95405626e-01,  5.60270727e-01, -2.90524423e-01,\n",
       "         1.25927806e-01,  8.76785517e-01,  3.26017410e-01,\n",
       "        -1.10184245e-01,  9.75554049e-01,  9.67438519e-01,\n",
       "         8.51520836e-01, -1.73586700e-02,  4.85467345e-01,\n",
       "        -4.77020323e-01,  5.96388839e-02,  7.11490929e-01,\n",
       "         1.03169727e+00, -1.15989435e+00,  8.23687613e-02,\n",
       "        -7.22351253e-01,  1.24562256e-01, -2.54514575e-01,\n",
       "         1.26424277e+00,  6.46375299e-01,  6.11390293e-01,\n",
       "        -4.11301851e-01,  4.13277954e-01, -5.14430523e-01,\n",
       "        -5.35857856e-01, -1.58056331e+00, -1.09976098e-01,\n",
       "         5.31880617e-01, -1.69358954e-01,  3.01608056e-01,\n",
       "         4.92446184e-01, -4.46183383e-02,  1.01508230e-01,\n",
       "        -6.40470684e-01,  4.90078479e-01,  8.47642720e-02,\n",
       "        -8.80842030e-01,  9.62690830e-01, -7.17536449e-01,\n",
       "         2.68033653e-01,  3.34250689e-01,  3.02061528e-01,\n",
       "         1.01219475e+00,  4.40674752e-01, -7.54340112e-01,\n",
       "         1.33159149e+00,  1.76233411e-01, -3.56840249e-03,\n",
       "        -7.01469108e-02,  4.18420553e-01, -1.22106239e-01,\n",
       "        -6.49473011e-01, -8.72004092e-01, -2.66984373e-01,\n",
       "        -1.99847236e-01, -5.77115297e-01,  2.13473409e-01,\n",
       "        -5.63289464e-01, -3.67020756e-01,  1.31094718e+00,\n",
       "         1.02180675e-01,  2.00238265e-03, -3.19756269e-01,\n",
       "        -1.11407213e-01, -9.18636680e-01, -6.86113656e-01,\n",
       "        -3.27235371e-01, -4.83928412e-01,  4.96155143e-01,\n",
       "         3.37974191e-01, -5.69079211e-03, -4.06559944e-01,\n",
       "        -2.29661062e-01, -5.41274667e-01,  6.16285384e-01,\n",
       "         1.18508184e+00, -1.55194908e-01, -1.07818872e-01,\n",
       "         3.48817110e-01, -1.50151953e-01,  5.23920834e-01,\n",
       "        -4.80885394e-02, -4.07294571e-01, -6.01872385e-01,\n",
       "        -1.95335507e-01, -3.72423619e-01,  7.04783738e-01,\n",
       "         6.77857041e-01,  9.27444547e-02,  5.82526565e-01,\n",
       "        -9.36190963e-01,  8.72395694e-01,  7.20267713e-01,\n",
       "        -3.15929025e-01, -1.09501970e+00, -2.33510196e-01,\n",
       "         5.44775188e-01,  1.00926340e+00, -3.40549618e-01,\n",
       "         1.07640111e+00,  6.00054502e-01,  6.97900414e-01,\n",
       "         3.14389229e-01, -3.77317071e-02,  8.79518569e-01,\n",
       "        -3.57611448e-01,  2.82133132e-01, -2.11631119e-01,\n",
       "         1.17547238e+00,  1.02055454e+00, -7.01008081e-01,\n",
       "        -5.34856558e-01,  1.03486383e+00,  1.06862926e+00,\n",
       "        -2.80053075e-02, -8.95805478e-01,  8.26368511e-01,\n",
       "        -1.12078834e+00, -2.95537207e-02,  2.54203290e-01,\n",
       "        -4.90741253e-01,  1.88738778e-01,  1.01574518e-01,\n",
       "        -2.01791257e-01, -2.47782752e-01, -1.64336320e-02,\n",
       "         4.44653451e-01,  6.97466671e-01, -1.61247063e+00,\n",
       "        -5.74855566e-01, -1.66385007e+00,  1.16780591e+00,\n",
       "         1.12595582e+00, -2.85130143e-01, -1.11169505e+00,\n",
       "        -2.44633511e-01, -7.81623721e-01, -4.91343230e-01,\n",
       "        -6.64467096e-01,  3.52208495e-01,  2.49924466e-01,\n",
       "        -6.07847452e-01,  4.94842790e-02,  1.90955177e-01,\n",
       "        -2.98112005e-01, -3.94658178e-01, -1.94369569e-01,\n",
       "         8.38672876e-01,  9.65449512e-02, -9.40853894e-01,\n",
       "         1.65289092e+00,  1.46222961e+00, -8.50405812e-01,\n",
       "         2.62614340e-01,  3.56718332e-01, -4.91758585e-02,\n",
       "        -1.60745800e+00,  1.77996755e-01, -1.06534258e-01,\n",
       "         7.81584740e-01, -1.50275445e+00,  7.33633757e-01,\n",
       "         1.59927204e-01,  8.97012413e-01, -8.28496873e-01,\n",
       "        -6.01882756e-01,  1.07125171e-01, -7.72005737e-01,\n",
       "        -1.06821346e+00,  5.68530321e-01, -3.61152232e-01,\n",
       "         7.71932840e-01,  6.34333193e-01,  2.33368143e-01,\n",
       "         4.51009631e-01,  3.52616042e-01,  1.81548297e-01,\n",
       "        -1.78964138e-01,  9.92294312e-01,  1.53814808e-01,\n",
       "         1.18509531e+00,  1.09893441e+00,  1.53181851e+00,\n",
       "        -3.25809717e-01,  1.12649953e+00,  2.46699050e-01,\n",
       "        -5.26391827e-02, -6.60780311e-01, -1.74190998e-01,\n",
       "         1.96127102e-01,  1.75944924e-01,  1.10588813e+00,\n",
       "         5.80416769e-02,  9.72166777e-01,  4.08480614e-01,\n",
       "        -7.56394148e-01, -8.49899232e-01, -8.43931794e-01,\n",
       "         3.11964273e-01, -6.41584933e-01, -1.12411427e+00,\n",
       "         5.14616847e-01, -5.13652086e-01,  6.91243261e-02,\n",
       "        -2.54454494e-01, -1.75507396e-01, -4.84346122e-01,\n",
       "         7.40397573e-01, -1.40436661e+00, -1.24591422e+00,\n",
       "        -1.19173956e+00, -6.11769795e-01, -9.64673422e-03,\n",
       "        -3.71770799e-01, -3.37596387e-01,  4.08069283e-01,\n",
       "        -9.60415900e-01,  3.05246651e-01, -8.17108899e-02,\n",
       "        -1.57855749e-01,  1.26189113e+00,  9.38912690e-01,\n",
       "        -2.26750016e-01, -1.31534822e-02,  3.77148718e-01,\n",
       "         1.52708843e-01, -1.67084670e+00,  5.86596489e-01,\n",
       "        -1.65307775e-01, -4.80762780e-01,  9.08698559e-01,\n",
       "         1.09380376e+00,  3.21322858e-01,  1.17350769e+00,\n",
       "        -4.17351514e-01, -5.75754941e-01, -1.55621576e+00,\n",
       "        -2.62866110e-01, -8.95098805e-01, -1.13614464e+00,\n",
       "        -1.85218513e-01, -8.37834299e-01,  1.08289349e+00,\n",
       "        -1.84007660e-02, -3.74013364e-01,  3.22678477e-01,\n",
       "        -2.29183704e-01,  6.31587207e-02, -2.45787352e-01,\n",
       "        -1.30978078e-01,  2.65543349e-03,  7.73789048e-01,\n",
       "        -5.98292589e-01,  7.04214394e-01,  1.11298454e+00,\n",
       "        -4.59253013e-01,  7.18858957e-01,  1.27645659e+00,\n",
       "         4.11471814e-01, -1.35269129e+00, -4.41063821e-01,\n",
       "         5.28330624e-01,  2.17945075e+00,  1.81553274e-01,\n",
       "         4.93568480e-01,  1.62233040e-01, -7.76014328e-01,\n",
       "        -5.46157658e-01,  9.91900980e-01,  4.20796633e-01,\n",
       "         7.37363219e-01,  7.21236169e-02, -4.75137442e-01,\n",
       "         5.71656406e-01,  2.19130039e-01,  1.13981712e+00,\n",
       "         4.43226248e-02, -3.69413882e-01, -1.39230251e-01,\n",
       "        -6.72525167e-02, -5.54673433e-01,  9.03843522e-01,\n",
       "        -1.00345814e+00, -5.83490610e-01,  2.27843285e-01,\n",
       "         1.30701327e+00,  3.43420565e-01,  3.85057300e-01,\n",
       "        -1.06338227e+00,  4.35220599e-02, -9.82008755e-01,\n",
       "        -1.07608891e+00, -3.98558885e-01, -4.84202020e-02,\n",
       "         1.54085919e-01,  3.94212306e-01, -7.93642223e-01,\n",
       "         1.55690241e+00, -1.22928667e+00,  1.43323883e-01,\n",
       "        -1.04023230e+00, -1.73563087e+00,  7.73105502e-01,\n",
       "        -2.99850851e-01, -8.60811889e-01,  7.47131705e-01,\n",
       "        -1.02405512e+00, -1.56557605e-01,  1.85035095e-01,\n",
       "        -4.43541594e-02,  6.90647840e-01,  4.78408217e-01,\n",
       "        -3.37817550e-01,  1.09445751e+00, -6.55856550e-01,\n",
       "         3.70225251e-01, -6.23082936e-01,  7.40464747e-01,\n",
       "         9.95316923e-01,  4.49062884e-01, -4.21951145e-01,\n",
       "         4.84030366e-01,  5.72482586e-01,  1.61066115e+00,\n",
       "        -1.18713188e+00,  5.95206320e-01,  5.54816544e-01,\n",
       "        -9.09428716e-01,  8.44264805e-01, -2.85520822e-01,\n",
       "         1.92872241e-01, -1.30195335e-01, -1.08016324e+00,\n",
       "        -6.37947977e-01, -1.15314096e-01, -5.40270746e-01,\n",
       "         2.92729259e-01, -4.56988603e-01,  5.50751686e-01,\n",
       "         5.41159101e-02,  3.07176620e-01, -1.09013212e+00,\n",
       "         8.03909838e-01,  3.28006983e-01, -9.41140711e-01,\n",
       "         2.09789604e-01,  2.21428156e-01,  4.64936942e-01,\n",
       "         1.48806965e+00,  2.11455435e-01,  3.15588862e-01,\n",
       "        -7.88373530e-01,  8.09860468e-01,  3.56072873e-01,\n",
       "         6.03842854e-01, -7.72774458e-01,  1.53662547e-01,\n",
       "        -4.37804878e-01,  5.96320748e-01, -5.05119205e-01,\n",
       "        -4.83519286e-01,  6.32266045e-01, -9.53049421e-01,\n",
       "        -9.90050614e-01,  1.88809291e-01,  1.24075308e-01,\n",
       "         3.67214859e-01,  3.36881667e-01,  2.87710689e-02,\n",
       "        -9.74179864e-01, -7.74128437e-01,  3.71041179e-01,\n",
       "         1.41170487e-01,  1.41216949e-01, -5.08933306e-01,\n",
       "        -9.89637434e-01, -8.14207971e-01, -1.02106643e+00,\n",
       "         1.21865785e+00, -3.20482373e-01, -1.06869781e+00,\n",
       "         1.19973552e+00, -3.75763178e-01,  4.01827365e-01,\n",
       "        -9.43629086e-01, -2.84526974e-01,  8.67513895e-01,\n",
       "         8.96539688e-01,  4.43521403e-02,  1.63348675e+00,\n",
       "         2.74311990e-01, -4.47422676e-02, -2.39584789e-01,\n",
       "        -2.18181074e-01, -1.11006320e+00, -2.92209774e-01,\n",
       "        -5.99836409e-01,  8.59964907e-01,  7.70198762e-01,\n",
       "        -1.87940355e-02,  8.77819419e-01, -2.21596770e-02,\n",
       "         4.03593294e-04,  7.44955838e-01, -1.41582406e+00,\n",
       "        -1.20759976e+00, -9.52215850e-01,  8.62923086e-01,\n",
       "         2.17971683e-01,  1.69861205e-02,  2.84667134e-01,\n",
       "        -6.67515397e-01, -2.32937604e-01, -1.42749465e+00,\n",
       "        -9.87537622e-01, -1.30462396e+00, -4.07197952e-01,\n",
       "         1.24683344e+00,  6.20674312e-01,  4.22553927e-01,\n",
       "         1.43956590e+00, -5.62765419e-01, -5.06788254e-01,\n",
       "         3.15194547e-01,  6.54325783e-02,  3.29030119e-03,\n",
       "         7.35645950e-01, -5.22485912e-01,  4.48861420e-01,\n",
       "        -1.45174563e-01,  4.89126056e-01, -7.34110415e-01,\n",
       "        -7.94649661e-01, -3.25291246e-01,  4.99946654e-01,\n",
       "        -1.70921981e-01, -1.23221171e+00,  3.44175428e-01,\n",
       "         2.30440095e-01, -5.96863031e-01, -6.39026344e-01,\n",
       "        -9.91389036e-01, -5.21465540e-01, -1.08326411e+00,\n",
       "        -6.42103970e-01, -1.59480035e-01, -2.06590027e-01,\n",
       "        -7.29736209e-01, -1.82521090e-01, -4.44950014e-01,\n",
       "        -5.57219088e-01,  1.33152023e-01,  5.57961404e-01,\n",
       "         3.06293577e-01, -6.02318525e-01,  1.16197991e+00,\n",
       "        -6.27502203e-01,  6.41660154e-01, -7.21309632e-02,\n",
       "        -1.11230528e+00, -1.23006487e+00,  1.07048512e-01,\n",
       "         9.14471388e-01, -1.52727678e-01,  2.39014030e-01,\n",
       "         8.43645692e-01, -1.83885500e-01, -5.61932027e-01,\n",
       "        -1.47603583e+00,  2.25664511e-01,  6.89425945e-01,\n",
       "        -5.59990108e-01, -7.41115391e-01,  3.14012021e-01,\n",
       "         2.66424894e-01,  1.03633535e+00, -5.01422048e-01,\n",
       "        -4.86119509e-01,  7.62025654e-01, -6.76233411e-01,\n",
       "        -1.00191462e+00, -5.68542838e-01,  6.20104313e-01,\n",
       "         6.61168814e-01, -1.47421050e+00, -3.76017183e-01,\n",
       "        -2.06217721e-01, -8.13827932e-01,  9.83246148e-01,\n",
       "         2.73735970e-01,  1.17964640e-01,  3.22680622e-01,\n",
       "        -8.08479071e-01,  3.50904554e-01, -7.43738189e-02,\n",
       "         9.95196521e-01,  4.79892015e-01, -1.44451392e+00,\n",
       "        -3.24420094e-01, -3.22726294e-02,  9.02337134e-01,\n",
       "         5.01726866e-01, -1.58726901e-01, -2.99767461e-02,\n",
       "        -2.87524313e-01, -8.41476023e-01, -8.84078920e-01,\n",
       "         9.65846598e-01, -5.73637545e-01,  1.93575001e+00,\n",
       "        -1.21756601e+00, -3.34853917e-01,  7.64299810e-01,\n",
       "        -6.19924903e-01, -8.57056260e-01,  4.92973894e-01,\n",
       "        -4.66207206e-01,  1.49969709e+00, -5.67345202e-01,\n",
       "         7.23564684e-01, -9.74492133e-02, -1.85278088e-01,\n",
       "         1.08993053e-01,  6.13992572e-01,  1.04629374e+00,\n",
       "         5.94727337e-01, -2.62306780e-01,  1.16882697e-01,\n",
       "        -8.11815202e-01, -1.92119688e-01,  1.34391212e+00,\n",
       "         1.45511866e+00, -1.54397488e+00,  1.70457947e+00,\n",
       "        -3.45488032e-03,  1.00304353e+00, -9.33958530e-01,\n",
       "         6.15452588e-01,  3.32278460e-01, -1.05525267e+00,\n",
       "         1.31934695e-02, -7.38063335e-01,  1.06816895e-01,\n",
       "         6.52975857e-01,  4.34125572e-01,  2.74379075e-01,\n",
       "        -3.26803982e-01,  4.93598104e-01,  3.45628291e-01,\n",
       "        -7.81022191e-01,  9.25363839e-01,  4.64431226e-01,\n",
       "        -2.50199318e-01, -2.28867143e-01, -4.60351765e-01,\n",
       "        -5.69154322e-01,  7.38974035e-01, -7.80177951e-01,\n",
       "         6.91372812e-01, -2.37994745e-01,  9.26957309e-01,\n",
       "        -5.97515404e-02, -5.77865690e-02, -5.51142514e-01,\n",
       "        -3.91448706e-01, -1.36224031e-01,  1.14810932e+00,\n",
       "        -5.87756455e-01, -8.99019599e-01, -1.96231440e-01,\n",
       "        -4.94348973e-01, -2.16206998e-01,  6.55426383e-01,\n",
       "         4.11687881e-01, -4.54236925e-01, -5.48431724e-02,\n",
       "        -4.41543877e-01,  3.09213072e-01,  6.78566635e-01,\n",
       "        -1.27072275e-01, -2.29374707e-01,  1.45004690e+00,\n",
       "         7.17539012e-01, -1.15454280e+00, -1.14142632e+00,\n",
       "         1.96891248e-01, -3.71219099e-01, -5.96798658e-01,\n",
       "        -2.01417029e-01, -4.23944950e-01,  8.08392644e-01,\n",
       "        -3.72151017e-01,  2.97616959e-01,  4.62428153e-01,\n",
       "         1.30269015e+00,  2.45976925e-01, -1.50978833e-01]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exécution du modèle\n",
    "onnx_input = single_image_pipeline(\n",
    "    \"dataset/tomato/88614302-e6d2-4327-a4fb-a3db9c9ea72e___YLCV_NREC_2861.JPG\"\n",
    ")\n",
    "\n",
    "encoded_image = ort_session_encoder.run(None, {\"x\": onnx_input})[0]\n",
    "encoded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1.5312373e-06, 9.0133162e-06, 2.1658811e-06, 8.6138307e-06,\n",
       "         1.5698393e-05, 7.7833420e-06, 1.2598617e-06, 9.6167660e-06,\n",
       "         7.2367616e-06, 1.6960983e-05, 9.9992025e-01]], dtype=float32)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decoding\n",
    "decoded_output = ort_session_decoder.run(None, {\"x\": encoded_image})\n",
    "decoded_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5312e-06, 9.0133e-06, 2.1659e-06, 8.6138e-06, 1.5698e-05, 7.7833e-06,\n",
       "         1.2599e-06, 9.6167e-06, 7.2367e-06, 1.6961e-05, 9.9992e-01]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation avec pytorch\n",
    "torch_input = torch.tensor(onnx_input)\n",
    "encoded_image = inference_model_encoder(torch_input)\n",
    "decoded = inference_model_decoder(encoded_image)\n",
    "decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Modèle des plantes (MobileNet_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained MobileNet_v3\n",
    "num_labels = 3  # Get number of labels (e.g., 8)\n",
    "\n",
    "model = torchvision.models.mobilenet_v3_large(weights=\"IMAGENET1K_V1\")  # Load a pretrained model\n",
    "model.classifier[3] = torch.nn.Linear(\n",
    "    model.classifier[3].in_features, num_labels\n",
    ")  # Modify last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"models/plant_model_2025_03_21.pt\",\n",
    "        map_location=device,\n",
    "        weights_only=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5631, 0.0999, 0.3371]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create inference model\n",
    "inference_model = InferenceModel(model)\n",
    "inference_model.eval()\n",
    "\n",
    "test = torch.randn(224, 224, 3)\n",
    "inference_model(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `InferenceModel([...]` with `torch.export.export`...\n",
      "[torch.onnx] Obtain model graph for `InferenceModel([...]` with `torch.export.export`... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "Converting models with optimization style 'Fixed' and level 'all'\n",
      "Converting optimized ONNX model /home/maxime/Documents/Code/happybud/training/models/plant_model_2025_03_21.onnx to ORT format model /home/maxime/Documents/Code/happybud/training/models/plant_model_2025_03_21.ort\n",
      "Converted 1/1 models successfully.\n",
      "Generating config file from ORT format models with optimization style 'Fixed' and level 'all'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2025-03-24 11:57:08.222956453 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training__1' source:{16} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.222985784 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training__2' source:{16} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.223138959 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_1__1' source:{16} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.223153063 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_1__2' source:{16} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.223303115 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_2__1' source:{16} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.223317490 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_2__2' source:{16} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.223449816 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_3__1' source:{64} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.223463177 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_3__2' source:{64} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.223591502 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_4__1' source:{64} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.223604454 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_4__2' source:{64} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.223726374 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_5__1' source:{24} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.223739094 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_5__2' source:{24} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.223855486 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_6__1' source:{72} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.223868164 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_6__2' source:{72} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.223988147 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_7__1' source:{72} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.224000968 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_7__2' source:{72} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.224119776 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_8__1' source:{24} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.224132465 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_8__2' source:{24} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.224254653 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_9__1' source:{72} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.224277023 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_9__2' source:{72} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.224403765 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_10__1' source:{72} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.224417347 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_10__2' source:{72} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.224599419 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_11__1' source:{40} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.224611866 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_11__2' source:{40} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.224721625 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_12__1' source:{120} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.224733837 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_12__2' source:{120} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.224849180 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_13__1' source:{120} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.224861630 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_13__2' source:{120} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.225026511 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_14__1' source:{40} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.225039360 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_14__2' source:{40} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.225158578 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_15__1' source:{120} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.225171230 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_15__2' source:{120} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.225317767 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_16__1' source:{120} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.225331587 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_16__2' source:{120} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.225497159 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_17__1' source:{40} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.225509860 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_17__2' source:{40} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.225632186 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_18__1' source:{240} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.225644704 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_18__2' source:{240} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.225772958 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_19__1' source:{240} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.225785874 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_19__2' source:{240} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.225907342 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_20__1' source:{80} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.225919781 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_20__2' source:{80} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.226033960 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_21__1' source:{200} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.226046563 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_21__2' source:{200} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.226170217 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_22__1' source:{200} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.226182486 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_22__2' source:{200} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.226322462 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_23__1' source:{80} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.226336164 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_23__2' source:{80} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.226455388 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_24__1' source:{184} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.226467794 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_24__2' source:{184} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.226587613 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_25__1' source:{184} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.226600187 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_25__2' source:{184} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.226723211 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_26__1' source:{80} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.226735787 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_26__2' source:{80} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.226858097 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_27__1' source:{184} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.226870772 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_27__2' source:{184} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.226998215 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_28__1' source:{184} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.227010457 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_28__2' source:{184} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.227134902 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_29__1' source:{80} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.227147174 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_29__2' source:{80} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.227263706 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_30__1' source:{480} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.227291100 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_30__2' source:{480} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.227413795 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_31__1' source:{480} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.227425939 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_31__2' source:{480} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.227595685 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_32__1' source:{112} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.227608257 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_32__2' source:{112} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.227718886 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_33__1' source:{672} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.227731170 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_33__2' source:{672} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.227856827 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_34__1' source:{672} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.227869229 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_34__2' source:{672} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.228042287 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_35__1' source:{112} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.228055570 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_35__2' source:{112} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.228183542 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_36__1' source:{672} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.228195922 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_36__2' source:{672} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.228334928 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_37__1' source:{672} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.228348319 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_37__2' source:{672} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.228513903 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_38__1' source:{160} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.228526280 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_38__2' source:{160} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.228636535 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_39__1' source:{960} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.228648710 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_39__2' source:{960} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.228768350 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_40__1' source:{960} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.228780563 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_40__2' source:{960} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.228947096 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_41__1' source:{160} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.228959486 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_41__2' source:{160} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229076223 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_42__1' source:{960} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229088438 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_42__2' source:{960} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229208217 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_43__1' source:{960} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229220603 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_43__2' source:{960} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229391522 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_44__1' source:{160} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229404609 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_44__2' source:{160} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229521546 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_45__1' source:{960} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229533772 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_45__2' source:{960} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229829007 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_154'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229836318 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_146'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229840815 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_143'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229845374 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_132'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229849679 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_129'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229854020 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_124'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229858276 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_151'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229862290 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_121'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229866456 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_113'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229870758 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_107'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229875290 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_96'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229879441 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_93'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229883674 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_90'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229887820 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_87'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229892127 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_84'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229896216 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_81'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229900367 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_72'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229904840 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_69'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229908908 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_66'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229913246 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_60'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229918977 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_52'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229923132 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_49'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229927273 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_44'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229931717 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_29'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229935913 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_26'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229940077 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_23'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229944179 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_11'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229948465 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_5'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229953136 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.16.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229959162 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_135'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229963357 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.14.block.0.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229968684 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.13.block.1.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229973086 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.13.block.0.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229978294 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.12.block.1.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229982690 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.12.block.0.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229987615 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.11.block.1.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229992344 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.11.block.0.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.229997431 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_32'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230002676 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.10.block.1.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230011281 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.7.block.2.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230018033 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.12.block.3.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230023088 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.1.block.1.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230029277 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.15.block.1.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230037988 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.15.block.0.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230043808 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.11.block.3.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230048993 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.8.block.0.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230054186 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_20'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230058660 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.10.block.0.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230063970 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_55'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230072654 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_140'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230077689 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.10.block.2.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230082283 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.15.block.3.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230086896 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.3.block.2.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230092579 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_75'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230097406 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.14.block.3.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230102743 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.14.block.1.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230108858 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.2.block.1.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230113823 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.9.block.2.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230118812 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_102'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230127198 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_99'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230131349 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.13.block.3.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230137248 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.3.block.1.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230141607 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_17'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230148365 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_38'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230155186 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_2'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230160954 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_8'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230166109 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_14'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230172969 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.4.block.0.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230177390 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.6.block.3.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230182265 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.9.block.0.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230186581 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_78'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230191124 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.0.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230195858 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.8.block.2.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230200700 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_63'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230204912 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.1.block.0.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230209391 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_118'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230213704 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.5.block.3.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230218475 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.2.block.2.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230223441 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.3.block.0.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230228885 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.4.block.1.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230233842 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.4.block.3.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230237991 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_41'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230242696 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.5.block.0.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230246833 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.5.block.1.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230251702 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.2.block.0.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230255999 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.6.block.0.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230260218 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_110'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230274438 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.6.block.1.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230280527 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.7.block.0.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230284993 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.7.block.1.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230290126 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.8.block.1.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 11:57:08.230295234 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.9.block.1.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "2025-03-24 11:57:08,393 ort_format_model.utils [INFO] - Created config in /home/maxime/Documents/Code/happybud/training/models/plant_model_2025_03_21.required_operators.config\n"
     ]
    }
   ],
   "source": [
    "torch_input = torch.randn(224, 224, 3)\n",
    "export_to_onnx(inference_model, torch_input, \"plant_model_2025_03_21\", \"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(\n",
    "    \"models/plant_model_2025_03_21.ort\", providers=[\"CPUExecutionProvider\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[8.8753900e-08, 9.9999964e-01, 2.4354483e-07]], dtype=float32)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exécution du modèle\n",
    "onnx_input = single_image_pipeline(\n",
    "    \"dataset/tomato/88614302-e6d2-4327-a4fb-a3db9c9ea72e___YLCV_NREC_2861.JPG\"\n",
    ")\n",
    "\n",
    "onnxruntime_outputs = ort_session.run(None, {\"x\": onnx_input})\n",
    "onnxruntime_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.8754e-08, 1.0000e+00, 2.4355e-07]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exécution sur pytorch pour comparer\n",
    "torch_input = torch.tensor(onnx_input)\n",
    "inference_model(torch_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Modèle des plantes (encoder - decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained MobileNet_v3\n",
    "num_labels = 3  # Get number of labels (e.g., 8)\n",
    "\n",
    "model = torchvision.models.mobilenet_v3_large(weights=\"IMAGENET1K_V1\")  # Load a pretrained model\n",
    "model.classifier[3] = torch.nn.Linear(\n",
    "    model.classifier[3].in_features, num_labels\n",
    ")  # Modify last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"models/plant_model_2025_03_21.pt\",\n",
    "        map_location=device,\n",
    "        weights_only=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV3(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
       "          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (16): Conv2dNormActivation(\n",
       "      (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=960, out_features=1280, bias=True)\n",
       "    (1): Hardswish()\n",
       "    (2): Dropout(p=0.2, inplace=True)\n",
       "    (3): Linear(in_features=1280, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract classifier\n",
    "classifier = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features=960, out_features=1280, bias=True),\n",
    "    torch.nn.Hardswish(),\n",
    "    torch.nn.Dropout(p=0.2, inplace=True),\n",
    "    torch.nn.Linear(in_features=1280, out_features=3, bias=True),\n",
    ")\n",
    "\n",
    "for i in range(4):\n",
    "    if hasattr(classifier[i], \"weight\"):\n",
    "        classifier[i].weight = model.classifier[i].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model classifier to identity\n",
    "model.classifier = torch.nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InferenceModelDecoder(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=960, out_features=1280, bias=True)\n",
       "    (1): Hardswish()\n",
       "    (2): Dropout(p=0.2, inplace=True)\n",
       "    (3): Linear(in_features=1280, out_features=3, bias=True)\n",
       "  )\n",
       "  (postprocess): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define encoder and decoder inference models\n",
    "inference_model_encoder = InferenceModelEncoder(model)\n",
    "inference_model_decoder = InferenceModelDecoder(classifier)\n",
    "\n",
    "inference_model_encoder.eval()\n",
    "inference_model_decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5725, 0.0806, 0.3469]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test inference model encoder and decoder\n",
    "torch_input = torch.randn(224, 224, 3)\n",
    "\n",
    "encoded = inference_model_encoder(torch_input)\n",
    "decoded = inference_model_decoder(encoded)\n",
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `InferenceModelEncoder([...]` with `torch.export.export`...\n",
      "[torch.onnx] Obtain model graph for `InferenceModelEncoder([...]` with `torch.export.export`... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "Converting models with optimization style 'Fixed' and level 'all'\n",
      "Converting optimized ONNX model /home/maxime/Documents/Code/happybud/training/models/plant_model_2025_03_21_encoder.onnx to ORT format model /home/maxime/Documents/Code/happybud/training/models/plant_model_2025_03_21_encoder.ort\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2025-03-24 12:13:21.028230552 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training__1' source:{16} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.028278056 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training__2' source:{16} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.028451079 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_1__1' source:{16} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.028467221 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_1__2' source:{16} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.028612897 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_2__1' source:{16} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.028627739 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_2__2' source:{16} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.028771336 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_3__1' source:{64} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.028785735 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_3__2' source:{64} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.028924006 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_4__1' source:{64} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.028938263 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_4__2' source:{64} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.029073546 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_5__1' source:{24} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.029087766 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_5__2' source:{24} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.029216059 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_6__1' source:{72} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.029230398 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_6__2' source:{72} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.029377303 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_7__1' source:{72} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.029392301 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_7__2' source:{72} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.029525250 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_8__1' source:{24} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.029539207 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_8__2' source:{24} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.029688688 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_9__1' source:{72} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.029702374 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_9__2' source:{72} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.029836396 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_10__1' source:{72} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.029850202 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_10__2' source:{72} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.030035884 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_11__1' source:{40} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.030049815 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_11__2' source:{40} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.030174048 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_12__1' source:{120} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.030188041 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_12__2' source:{120} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.030330414 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_13__1' source:{120} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.030345521 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_13__2' source:{120} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.030528808 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_14__1' source:{40} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.030542679 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_14__2' source:{40} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.030674008 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_15__1' source:{120} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.030687895 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_15__2' source:{120} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.030817008 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_16__1' source:{120} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.030831178 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_16__2' source:{120} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.031013527 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_17__1' source:{40} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.031027579 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_17__2' source:{40} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.031163501 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_18__1' source:{240} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.031178311 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_18__2' source:{240} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.031338444 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_19__1' source:{240} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.031353289 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_19__2' source:{240} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.031490326 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_20__1' source:{80} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.031503884 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_20__2' source:{80} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.031627033 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_21__1' source:{200} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.031640775 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_21__2' source:{200} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.031773424 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_22__1' source:{200} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.031787408 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_22__2' source:{200} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.031922441 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_23__1' source:{80} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.031935999 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_23__2' source:{80} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.032067179 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_24__1' source:{184} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.032080753 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_24__2' source:{184} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.032216734 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_25__1' source:{184} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.032230270 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_25__2' source:{184} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.032376059 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_26__1' source:{80} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.032390717 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_26__2' source:{80} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.032525521 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_27__1' source:{184} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.032539267 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_27__2' source:{184} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.032691963 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_28__1' source:{184} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.032705402 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_28__2' source:{184} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.032836600 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_29__1' source:{80} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.032849776 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_29__2' source:{80} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.032975610 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_30__1' source:{480} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.032989032 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_30__2' source:{480} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.033122588 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_31__1' source:{480} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.033136060 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_31__2' source:{480} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.033337190 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_32__1' source:{112} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.033352202 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_32__2' source:{112} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.033480819 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_33__1' source:{672} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.033494395 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_33__2' source:{672} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.033626607 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_34__1' source:{672} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.033640308 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_34__2' source:{672} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.033837619 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_35__1' source:{112} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.033852057 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_35__2' source:{112} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.033986793 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_36__1' source:{672} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.034000796 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_36__2' source:{672} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.034146911 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_37__1' source:{672} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.034160697 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_37__2' source:{672} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.034369962 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_38__1' source:{160} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.034384577 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_38__2' source:{160} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.034509842 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_39__1' source:{960} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.034523416 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_39__2' source:{960} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.034661062 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_40__1' source:{960} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.034674183 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_40__2' source:{960} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.034860094 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_41__1' source:{160} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.034873716 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_41__2' source:{160} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.035002198 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_42__1' source:{960} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.035015592 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_42__2' source:{960} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.035146560 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_43__1' source:{960} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.035159700 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_43__2' source:{960} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.035365381 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_44__1' source:{160} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.035382860 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_44__2' source:{160} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.035540109 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_45__1' source:{960} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.035555436 [W:onnxruntime:, graph.cc:109 MergeShapeInfo] Error merging shape info for output. '_native_batch_norm_legit_no_training_45__2' source:{960} target:{0}. Falling back to lenient merge.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036066626 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_154'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036081011 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_146'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036086456 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_143'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036091730 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_132'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036097631 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_129'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036102498 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_124'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036107475 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_151'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036112714 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_121'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036117404 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_113'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036122156 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_107'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036128556 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_96'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036133078 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_93'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036138002 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_90'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036142965 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_87'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036147790 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_84'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036152578 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_81'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036157917 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_72'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036163610 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_69'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036168132 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_66'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036173227 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_60'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036181156 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_52'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036186125 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_49'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036190944 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_44'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036196987 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_29'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036201983 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_26'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036206808 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_23'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036212144 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_11'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036217007 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_5'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036223194 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.16.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036231848 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_135'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036236682 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.14.block.0.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036243002 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.13.block.1.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036248877 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.13.block.0.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036256988 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.12.block.1.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036262432 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.12.block.0.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036281455 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.11.block.1.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036287643 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.11.block.0.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036293470 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_32'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036299708 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.10.block.1.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036310406 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.7.block.2.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036319752 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.12.block.3.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036326226 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.1.block.1.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036334424 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.15.block.1.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036346451 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.15.block.0.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036354218 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.11.block.3.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036361009 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.8.block.0.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036368321 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_20'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036375682 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_55'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036389709 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_140'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036395927 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.10.block.0.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036401384 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.10.block.2.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036406487 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.15.block.3.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036411904 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.3.block.2.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036419868 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_75'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036426778 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.14.block.3.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036433957 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.14.block.1.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036444084 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.2.block.1.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036451473 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_102'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036458546 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.6.block.3.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036475294 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_99'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036480041 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.13.block.3.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036489204 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.3.block.1.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036494751 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_17'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036505038 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_38'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036516646 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_2'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036525583 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_8'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036532409 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_14'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036541632 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.9.block.0.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036546460 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_78'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036552820 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.0.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036558931 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.8.block.2.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036563474 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_63'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036568420 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.1.block.0.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036574714 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_118'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036580311 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.5.block.3.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036586338 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.2.block.2.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036592704 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.3.block.0.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036599164 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.4.block.0.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036604858 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.4.block.1.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036611782 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.4.block.3.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036616714 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_41'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036623003 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.5.block.0.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036627878 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.5.block.1.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036633756 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.2.block.0.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036638869 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.6.block.0.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036644284 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_110'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036652056 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.6.block.1.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036657695 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.7.block.0.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036662348 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.7.block.1.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036667379 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.8.block.1.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036675213 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.9.block.1.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-24 12:13:21.036682791 [W:onnxruntime:, graph.cc:4285 CleanUnusedInitializersAndNodeArgs] Removing initializer 'model.features.9.block.2.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "2025-03-24 12:13:21,187 ort_format_model.utils [INFO] - Created config in /home/maxime/Documents/Code/happybud/training/models/plant_model_2025_03_21_encoder.required_operators.config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 1/1 models successfully.\n",
      "Generating config file from ORT format models with optimization style 'Fixed' and level 'all'\n",
      "[torch.onnx] Obtain model graph for `InferenceModelDecoder([...]` with `torch.export.export`...\n",
      "[torch.onnx] Obtain model graph for `InferenceModelDecoder([...]` with `torch.export.export`... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 12:13:22,200 ort_format_model.utils [INFO] - Created config in /home/maxime/Documents/Code/happybud/training/models/plant_model_2025_03_21_decoder.required_operators.config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "Converting models with optimization style 'Fixed' and level 'all'\n",
      "Converting optimized ONNX model /home/maxime/Documents/Code/happybud/training/models/plant_model_2025_03_21_decoder.onnx to ORT format model /home/maxime/Documents/Code/happybud/training/models/plant_model_2025_03_21_decoder.ort\n",
      "Converted 1/1 models successfully.\n",
      "Generating config file from ORT format models with optimization style 'Fixed' and level 'all'\n"
     ]
    }
   ],
   "source": [
    "# Export to ONNX\n",
    "export_to_onnx(inference_model_encoder, torch_input, \"plant_model_2025_03_21_encoder\", \"models\")\n",
    "export_to_onnx(inference_model_decoder, encoded, \"plant_model_2025_03_21_decoder\", \"models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation de l'exécution du modèle avec ONNX runtime (encoder decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "\n",
    "ort_session_encoder = onnxruntime.InferenceSession(\n",
    "    \"models/plant_model_2025_03_21_encoder.ort\", providers=[\"CPUExecutionProvider\"]\n",
    ")\n",
    "\n",
    "ort_session_decoder = onnxruntime.InferenceSession(\n",
    "    \"models/plant_model_2025_03_21_decoder.ort\", providers=[\"CPUExecutionProvider\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.20295122e-01,  1.10822761e+00,  2.06167065e-02,\n",
       "         5.83795369e-01,  4.89636898e-01,  1.52733281e-01,\n",
       "         5.86454690e-01,  5.68893135e-01,  9.34672773e-01,\n",
       "         1.25026953e+00,  2.63027608e-01,  9.86482501e-01,\n",
       "        -1.86756060e-01, -9.32499319e-02,  1.06694221e+00,\n",
       "         2.20941994e-02,  9.75903496e-02,  4.26993161e-01,\n",
       "         5.14855921e-01,  2.88239986e-01,  5.93492568e-01,\n",
       "         1.33377290e+00,  7.44929969e-01,  1.84211638e-02,\n",
       "         7.39451051e-01,  1.00868680e-01,  5.96427202e-01,\n",
       "        -1.47122145e-01, -6.02106117e-02,  5.33028424e-01,\n",
       "         7.59140551e-02,  3.94630909e-01,  1.37586761e-02,\n",
       "         1.46330446e-01,  2.03672722e-02,  7.63610303e-01,\n",
       "         1.22969377e+00, -1.37557238e-01,  2.83678591e-01,\n",
       "         2.23187178e-01,  1.00482710e-01,  6.73192292e-02,\n",
       "         1.07468821e-01, -8.61597806e-02,  9.62428987e-01,\n",
       "         1.76388443e+00,  6.88523173e-01, -1.79807290e-01,\n",
       "         1.05469506e-02,  5.82355917e-01,  6.89149229e-03,\n",
       "         4.08233851e-01,  1.17833269e+00,  1.83319759e+00,\n",
       "         1.19227254e+00,  4.09592688e-01,  7.76358366e-01,\n",
       "         1.06962109e+00,  1.09193158e+00,  4.37671393e-01,\n",
       "         9.87900376e-01,  6.55795753e-01,  1.31957686e+00,\n",
       "         3.17836851e-01,  1.12063336e+00,  7.82893658e-01,\n",
       "        -1.88942649e-03,  6.45313323e-01, -1.01191081e-01,\n",
       "        -1.69605210e-01,  9.58407938e-01,  1.27234817e+00,\n",
       "         1.65245444e-01,  1.12047382e-01,  1.36571813e+00,\n",
       "         9.88535285e-02,  1.49470061e-01, -1.22916281e-01,\n",
       "         1.29823223e-01,  2.43568663e-02, -1.22704558e-01,\n",
       "        -1.85461685e-01,  1.90157366e+00, -1.66584402e-01,\n",
       "         1.03740990e+00, -7.47039244e-02,  5.50049424e-01,\n",
       "         9.07866508e-02,  1.53082579e-01,  1.31875247e-01,\n",
       "         5.38857281e-01,  7.93335810e-02,  3.55884433e-01,\n",
       "         1.89838141e-01,  5.57199955e-01,  2.21046656e-01,\n",
       "         8.73854309e-02, -1.31117225e-01,  4.13761020e-01,\n",
       "         1.73168495e-01,  3.97556514e-01,  4.16575611e-01,\n",
       "         7.76707470e-01,  1.49072862e+00,  2.30894709e+00,\n",
       "         2.48912312e-02,  9.63547230e-01,  1.15707982e+00,\n",
       "        -1.32138491e-01,  7.14156330e-01,  3.63290310e-01,\n",
       "         1.27858952e-01, -1.52836397e-01,  1.30324984e+00,\n",
       "        -1.93708260e-02, -2.11258940e-02, -1.44519329e-01,\n",
       "        -6.18068725e-02,  1.19796116e-02,  1.12445094e-01,\n",
       "         8.69811296e-01,  1.30808103e+00,  1.11946833e+00,\n",
       "         3.47805828e-01, -1.23838477e-01, -1.68558594e-03,\n",
       "         4.69037533e-01,  3.74819070e-01,  4.48990971e-01,\n",
       "         9.77763385e-02,  3.57947171e-01,  1.10168791e+00,\n",
       "         3.64328861e-01,  5.89234173e-01,  2.16672316e-01,\n",
       "         5.37061036e-01,  1.28272071e-01,  3.45776856e-01,\n",
       "         7.58579150e-02,  7.63421893e-01,  6.47434235e-01,\n",
       "         8.70459318e-01,  3.34975958e-01,  8.01538944e-01,\n",
       "         6.22254014e-02,  8.27376008e-01,  4.81489539e-01,\n",
       "         4.49913263e-01,  2.12513709e+00,  1.45189539e-01,\n",
       "         2.48833317e-02,  6.79838955e-02,  6.59769893e-01,\n",
       "         4.08935785e-01, -1.11699305e-01,  6.44940376e-01,\n",
       "         1.38525987e+00,  3.87341857e-01,  1.15752697e+00,\n",
       "         5.33513308e-01,  5.24068654e-01,  8.62453699e-01,\n",
       "         5.19535899e-01,  1.18931389e+00,  5.37203550e-01,\n",
       "        -1.19419150e-01, -5.14519699e-02,  3.32608789e-01,\n",
       "         5.01752794e-01, -8.75310004e-02,  4.52291191e-01,\n",
       "         5.49306571e-01,  2.23987192e-01,  1.02233088e+00,\n",
       "         3.87290448e-01, -5.26846200e-02,  1.33646846e-01,\n",
       "         5.10773182e-01,  9.67698157e-01, -1.25355259e-01,\n",
       "         1.61568493e-01,  7.61658967e-01,  8.92817825e-02,\n",
       "         1.36818931e-01,  5.35942376e-01,  2.59781450e-01,\n",
       "         9.44947824e-02, -3.05858161e-02, -1.79196462e-01,\n",
       "         7.62335658e-01,  3.62869650e-01, -8.27248842e-02,\n",
       "        -4.11813892e-02,  5.13015747e-01,  6.11286201e-02,\n",
       "         3.62195998e-01,  8.02252114e-01,  1.31874710e-01,\n",
       "         7.27971613e-01, -1.64206520e-01,  9.06357050e-01,\n",
       "         4.38212991e-01,  6.98288500e-01,  4.84655410e-01,\n",
       "         3.77056122e-01,  9.54860091e-01,  3.85170072e-01,\n",
       "         1.15598559e+00, -2.17944868e-02, -1.88515559e-01,\n",
       "         6.24176860e-01,  1.57182321e-01, -1.56768486e-02,\n",
       "         1.98071346e-01,  5.15925527e-01,  8.86830091e-02,\n",
       "        -1.05248027e-01,  3.72580677e-01, -1.94651589e-01,\n",
       "        -1.38391316e-01, -1.70819536e-01,  6.21478558e-01,\n",
       "         1.28277779e+00,  1.32699400e-01,  3.34962308e-01,\n",
       "         9.79003489e-01, -1.23458348e-01, -1.19377621e-01,\n",
       "         4.73696254e-02,  7.12545514e-01,  3.93598467e-01,\n",
       "         1.75031388e+00,  2.71596879e-01, -6.35198355e-02,\n",
       "         1.18122530e+00,  3.15166235e-01,  7.34492540e-01,\n",
       "         1.34844518e+00,  2.09767193e-01, -1.59517512e-01,\n",
       "        -1.09443069e-01,  1.02289009e+00, -4.27872762e-02,\n",
       "         4.32866544e-01, -6.45478293e-02, -2.79562846e-02,\n",
       "         2.08532035e-01,  1.69385982e+00,  8.26230705e-01,\n",
       "         1.44344345e-01,  8.31676275e-02,  8.65666151e-01,\n",
       "         5.15446424e-01, -4.10425179e-02,  6.79285169e-01,\n",
       "         4.81129944e-01,  7.85179317e-01,  1.33377910e-01,\n",
       "         5.45863152e-01,  5.86870134e-01,  1.27929404e-01,\n",
       "         3.45354341e-02,  5.29459827e-02,  3.31812620e-01,\n",
       "         1.18429220e+00,  5.17285839e-02,  4.30751652e-01,\n",
       "         7.41424337e-02,  4.73503143e-01,  1.21505535e+00,\n",
       "         8.38481486e-02,  5.53073108e-01,  4.14142638e-01,\n",
       "        -8.29231665e-02,  6.64285064e-01,  2.09817111e-01,\n",
       "         6.61482334e-01,  4.43049252e-01,  3.23129714e-01,\n",
       "         4.73763764e-01,  2.90101767e-01,  4.36085939e-01,\n",
       "         6.71767235e-01,  6.90545559e-01,  3.72824639e-01,\n",
       "         1.04379177e+00,  1.30777538e+00,  6.59746289e-01,\n",
       "         1.01501071e+00, -1.08430512e-01,  4.89219278e-01,\n",
       "         4.78603274e-01, -1.08226590e-01,  7.92174876e-01,\n",
       "         5.39163649e-01,  1.13380110e+00,  1.04001796e+00,\n",
       "         1.72584879e+00,  4.53505546e-01,  6.35849476e-01,\n",
       "         1.05157420e-02,  1.04041862e+00,  3.61694694e-02,\n",
       "        -8.21956713e-03, -3.62869687e-02, -4.09279764e-02,\n",
       "         4.76980746e-01,  5.24224401e-01,  1.96110594e+00,\n",
       "        -3.22124921e-02,  1.99168396e+00,  1.47829759e+00,\n",
       "         1.16033721e+00,  4.32466149e-01,  4.07477826e-01,\n",
       "         1.51164070e-01,  4.85307723e-01,  1.72330841e-01,\n",
       "         6.80406466e-02, -7.50344172e-02,  5.93114436e-01,\n",
       "         1.12715077e+00,  2.48317450e-01, -8.34759697e-02,\n",
       "        -3.57455388e-02,  1.49383336e-01,  4.98624533e-01,\n",
       "         8.70538354e-01,  4.25486207e-01,  3.28558683e-01,\n",
       "        -1.31060749e-01,  8.29545319e-01,  5.27711093e-01,\n",
       "         1.37302071e-01,  5.51001072e-01,  8.18313897e-01,\n",
       "         6.88416302e-01, -1.96892470e-01,  4.82095242e-01,\n",
       "         4.50595856e-01,  7.57308081e-02,  5.34412086e-01,\n",
       "         1.76704144e+00,  1.45463288e-01,  2.58056164e-01,\n",
       "         1.70545709e+00,  3.73112917e-01,  2.27924019e-01,\n",
       "         1.48731411e-01,  3.85914475e-01,  5.59414387e-01,\n",
       "         3.29230011e-01,  7.54517138e-01,  3.69109921e-02,\n",
       "         3.47766638e-01,  2.66463995e-01,  2.04390779e-01,\n",
       "        -8.84112269e-02, -7.65216947e-02,  2.18044296e-01,\n",
       "         5.22652626e-01,  2.34395396e-02,  2.85041660e-01,\n",
       "         4.58654553e-01, -8.51397635e-05,  5.00322878e-01,\n",
       "         1.48858392e+00,  5.71384847e-01,  3.69765460e-01,\n",
       "        -1.58786830e-02,  5.53510129e-01,  3.44794422e-01,\n",
       "         2.29201376e-01, -8.43766555e-02,  7.91832209e-02,\n",
       "        -6.54186979e-02, -1.45675167e-01,  4.44296271e-01,\n",
       "         1.43936336e-01,  9.90913987e-01, -6.97700530e-02,\n",
       "         1.17447674e+00,  1.85858274e+00,  3.51231515e-01,\n",
       "        -9.55329612e-02,  1.38699487e-01,  3.72044384e-01,\n",
       "         6.65221885e-02,  3.89329821e-01,  2.77635783e-01,\n",
       "         2.11932555e-01, -8.78774077e-02,  3.04982722e-01,\n",
       "         1.89116883e+00,  6.39923573e-01,  1.20298266e+00,\n",
       "        -1.77642390e-01, -1.24144748e-01,  6.42097712e-01,\n",
       "         9.42338645e-01,  9.04808640e-01, -1.65508196e-01,\n",
       "        -3.79582569e-02,  4.47938651e-01,  3.21479708e-01,\n",
       "         1.71664394e-02,  5.27272940e-01, -1.60580963e-01,\n",
       "         1.00399101e+00,  7.28417456e-01, -1.36346161e-01,\n",
       "         1.67069390e-01,  7.18869567e-01,  2.32973814e-01,\n",
       "        -6.66813925e-02,  5.64176202e-01,  2.88781643e-01,\n",
       "         3.01228315e-01,  1.02112345e-01,  1.04709899e+00,\n",
       "         3.19674253e-01,  8.21782127e-02,  9.82498348e-01,\n",
       "         7.92224824e-01,  8.21146846e-01,  8.55412856e-02,\n",
       "         1.57655787e+00,  1.31011844e+00,  3.92079175e-01,\n",
       "         5.34935109e-02,  7.51865089e-01,  1.20195389e+00,\n",
       "         6.50205255e-01,  8.48279595e-02,  5.84208071e-01,\n",
       "         8.40125263e-01,  8.01848546e-02, -7.24601150e-02,\n",
       "         3.67718607e-01,  1.51305830e+00,  1.16506472e-01,\n",
       "         1.10242212e+00,  3.07922456e-02, -1.73861578e-01,\n",
       "         3.96471322e-01,  6.04627430e-01,  2.99639460e-02,\n",
       "         1.49683863e-01, -5.37711754e-02,  5.15294611e-01,\n",
       "        -3.16996798e-02,  5.69065273e-01,  7.54502833e-01,\n",
       "         4.66912955e-01,  1.48294806e-01,  6.98233545e-02,\n",
       "         8.44690919e-01, -1.80514738e-01,  1.59433767e-01,\n",
       "         7.09254742e-01,  1.00076413e+00, -8.08566734e-02,\n",
       "        -3.55886482e-02,  8.01573217e-01,  1.73277557e-01,\n",
       "         1.13752544e-01, -1.76246792e-01,  3.15863453e-02,\n",
       "         3.03288549e-01,  4.18151543e-02,  4.12349194e-01,\n",
       "         1.11374116e+00,  2.43533537e-01,  8.29716980e-01,\n",
       "         1.61199903e+00, -1.36079073e-01, -1.67893786e-02,\n",
       "        -6.11887462e-02,  2.85786986e-01,  3.69142056e-01,\n",
       "         2.49708161e-01,  1.18037581e+00,  2.77096659e-01,\n",
       "         1.85238466e-01,  1.72728583e-01, -1.70783490e-01,\n",
       "        -1.77622736e-01, -9.32870209e-02,  2.36881271e-01,\n",
       "        -1.81222677e-01,  1.75589621e-01,  4.47342433e-02,\n",
       "         1.07652009e+00,  9.73740220e-01,  3.02064747e-01,\n",
       "         7.70141304e-01,  1.70608327e-01,  6.41001701e-01,\n",
       "        -7.69934058e-02,  3.81338775e-01,  2.58551612e-02,\n",
       "         5.03514051e-01,  9.81935978e-01,  7.18839467e-01,\n",
       "         1.41718294e-02,  1.90807074e-01, -1.35377511e-01,\n",
       "         9.78157818e-01, -4.80990373e-02,  1.20945072e+00,\n",
       "         1.30247033e+00,  1.05287611e-01, -6.00566715e-02,\n",
       "         8.02964866e-01,  9.45520625e-02, -1.95918798e-01,\n",
       "         5.92193961e-01, -6.61184713e-02, -9.15521830e-02,\n",
       "         7.70480037e-02, -1.72827795e-01, -3.46146226e-02,\n",
       "        -1.53396979e-01,  1.00556993e+00,  8.01133275e-01,\n",
       "         1.23810530e+00, -1.53635576e-01,  1.70569515e+00,\n",
       "         4.51756448e-01,  1.51025444e-01,  3.45773220e-01,\n",
       "         1.37258875e+00,  4.07497644e-01,  6.05777949e-02,\n",
       "         4.39930195e-03,  1.89351127e-01, -9.32805985e-02,\n",
       "         5.35901606e-01,  7.67320454e-01, -1.66797131e-01,\n",
       "         2.71626681e-01,  3.28891754e-01,  1.85242951e-01,\n",
       "         6.93993390e-01,  1.86566800e-01, -1.01220608e-01,\n",
       "         6.35274649e-01,  9.83886480e-01, -5.55447526e-02,\n",
       "         8.96411240e-02,  4.40626025e-01,  4.34993893e-01,\n",
       "         9.02899727e-02,  6.48470402e-01, -1.66681752e-01,\n",
       "         7.35967219e-01,  9.00457442e-01, -1.24998987e-01,\n",
       "         4.14916068e-01,  8.04235101e-01,  1.31854415e-01,\n",
       "         2.24587774e+00,  9.99819279e-01,  1.12722409e+00,\n",
       "         1.48761317e-01,  1.50470173e+00,  4.79542524e-01,\n",
       "        -1.10658132e-01,  1.65689790e+00,  3.64930004e-01,\n",
       "         6.14304356e-02,  5.93921185e-01,  7.11073816e-01,\n",
       "         4.12128493e-02, -1.03810914e-02,  7.10512921e-02,\n",
       "         7.85953701e-01,  3.66810948e-01,  4.44292240e-02,\n",
       "         1.03654420e+00, -1.32181689e-01,  1.39463153e-02,\n",
       "         1.03891826e+00, -3.10023106e-03, -1.33167282e-01,\n",
       "         4.97165412e-01,  4.75780576e-01, -4.60825600e-02,\n",
       "        -6.77323565e-02,  1.44928133e+00,  1.34293163e+00,\n",
       "        -7.14875907e-02, -1.52412787e-01,  1.43297029e+00,\n",
       "         6.35039330e-01,  5.83391301e-02, -2.15773880e-02,\n",
       "         3.41625750e-01,  6.09851956e-01, -9.92741212e-02,\n",
       "         3.09242904e-01,  8.82763684e-01,  1.36672482e-01,\n",
       "         1.47603244e-01,  4.02973652e-01,  9.06090260e-01,\n",
       "         8.94971967e-01,  1.25221670e+00,  4.13697094e-01,\n",
       "         2.74479330e-01, -1.96029037e-01,  1.53753728e-01,\n",
       "         7.27925599e-02, -5.60688935e-02,  1.52429670e-01,\n",
       "         4.10770893e-01,  3.59416991e-01,  5.53982377e-01,\n",
       "         2.23679662e-01, -5.08730933e-02,  7.92648613e-01,\n",
       "         6.34757400e-01,  3.90303463e-01,  1.20038152e-01,\n",
       "         6.55402839e-01,  9.28182244e-01,  3.21915716e-01,\n",
       "         3.86768341e-01, -1.34341568e-01,  1.66536972e-01,\n",
       "        -1.32035881e-01,  3.63637418e-01,  6.47349581e-02,\n",
       "         6.86854646e-02,  1.08159101e+00, -1.06225803e-01,\n",
       "         1.12275994e+00,  3.42286795e-01, -9.91256684e-02,\n",
       "         3.31907012e-02, -1.45133734e-01,  4.80909765e-01,\n",
       "        -1.08780384e-01,  1.95589364e-01, -1.07782371e-01,\n",
       "         1.91403031e-01,  1.33974087e+00,  7.99764022e-02,\n",
       "         4.52375323e-01,  2.48251200e-01,  2.72694588e-01,\n",
       "         1.36013949e+00,  5.82830012e-01, -5.94079196e-02,\n",
       "         8.30068469e-01, -2.13215165e-02,  7.01390922e-01,\n",
       "         3.12148124e-01,  6.33753657e-01,  1.16136360e+00,\n",
       "        -2.15241179e-01,  4.08757150e-01,  2.90362686e-01,\n",
       "         4.07738596e-01,  3.76729608e-01,  5.74675202e-01,\n",
       "         1.95117407e-02,  2.54723638e-01,  7.02229701e-03,\n",
       "         3.07213292e-02,  1.67499065e+00,  2.46630907e-01,\n",
       "         7.98380971e-01, -1.88554868e-01, -2.04988211e-01,\n",
       "         4.72052634e-01, -4.97800335e-02,  1.37435460e+00,\n",
       "         5.03805935e-01,  3.28823239e-01,  2.38487169e-01,\n",
       "         1.83621526e-01,  2.01136589e-01,  6.26030147e-01,\n",
       "         4.34021838e-02,  9.61497426e-01,  7.39196599e-01,\n",
       "         4.62334342e-02, -6.69066533e-02, -5.06993085e-02,\n",
       "         3.11627805e-01,  3.22073884e-02,  4.66760099e-01,\n",
       "         9.82360542e-01,  5.42798936e-01,  1.41327763e+00,\n",
       "         2.60547936e-01,  8.39830041e-01,  1.36440289e+00,\n",
       "         1.98006511e-01, -1.02452345e-01,  4.16545272e-02,\n",
       "         5.32315314e-01,  1.14543259e+00,  1.08233607e+00,\n",
       "         2.82367975e-01, -2.00986534e-01,  4.22168255e-01,\n",
       "         8.79201174e-01,  4.70826358e-01,  1.22628319e+00,\n",
       "         1.32214653e+00,  3.85481596e-01, -1.07658900e-01,\n",
       "        -1.14862144e-01, -2.23040711e-02,  3.03681731e-01,\n",
       "         2.34215689e+00,  6.93102106e-02, -1.69590622e-01,\n",
       "         6.25438631e-01,  1.95003059e-02,  6.15040243e-01,\n",
       "         4.22329875e-03,  1.77634493e-01,  7.85892963e-01,\n",
       "         4.05930936e-01,  1.03813529e+00, -1.11316971e-01,\n",
       "         5.19662857e-01,  2.98578173e-01, -5.90446182e-02,\n",
       "         8.70255470e-01, -2.37818584e-02,  7.46904433e-01,\n",
       "         6.29684478e-02,  1.15488791e+00,  1.03039587e+00,\n",
       "         1.04415312e-01,  5.75700283e-01,  2.27231622e-01,\n",
       "        -6.21822327e-02,  1.98504567e-01,  6.88826740e-01,\n",
       "         5.39045155e-01, -7.50411153e-02,  6.71529114e-01,\n",
       "         5.20314813e-01,  4.92858365e-02, -1.93419263e-01,\n",
       "         5.61727226e-01,  5.47008038e-01, -5.23571782e-02,\n",
       "         4.32228446e-01,  1.43326879e+00, -4.95310947e-02,\n",
       "         3.40389460e-01, -1.54499173e-01,  5.45485735e-01,\n",
       "         2.71501124e-01,  7.77157068e-01,  4.57577229e-01,\n",
       "         9.50316414e-02, -5.81179606e-03,  1.12106133e+00,\n",
       "         1.23532188e+00,  2.48158440e-01,  1.14381462e-01,\n",
       "         1.42638481e+00,  1.64372170e+00,  3.71644236e-02,\n",
       "         2.52042085e-01,  2.07441136e-01,  8.97644907e-02,\n",
       "        -9.21497568e-02,  1.55717626e-01,  3.19815248e-01,\n",
       "         8.29353869e-01,  3.41984406e-02,  3.68988737e-02,\n",
       "         1.24757123e+00,  4.68244344e-01,  9.96868372e-01,\n",
       "         4.31754142e-01,  7.74069667e-01,  3.30789953e-01,\n",
       "         4.83789355e-01,  3.80767621e-02,  6.48773432e-01,\n",
       "        -2.42592409e-01,  1.18946791e+00,  3.13674480e-01,\n",
       "         1.02365792e+00, -9.78043862e-03,  7.92341113e-01,\n",
       "         7.99468994e-01,  4.62705016e-01,  2.26884276e-01,\n",
       "         2.44965792e-01,  3.36030722e-01,  5.06295443e-01,\n",
       "         1.05980444e+00,  1.07700396e+00,  6.53864503e-01,\n",
       "         9.64464247e-01, -1.47315621e-01,  4.01902616e-01,\n",
       "         4.75444883e-01,  7.39812255e-01,  5.36597610e-01,\n",
       "         9.13609087e-01,  1.35763690e-01,  4.63247895e-01,\n",
       "         1.26793623e+00,  1.71168065e+00, -1.11434884e-01,\n",
       "         6.63325489e-01,  1.93377328e+00,  1.52969852e-01,\n",
       "         2.76388228e-01, -7.27592334e-02,  1.19388211e+00,\n",
       "         5.62740624e-01,  9.65291709e-02,  1.01904476e+00,\n",
       "         1.27241611e-01,  8.78521800e-01,  6.26120493e-02,\n",
       "        -8.80798623e-02, -1.69232443e-01, -2.78544873e-02,\n",
       "         1.14864254e+00,  5.93151510e-01,  3.91729981e-01,\n",
       "        -3.78459245e-02,  3.71603668e-02,  1.16503465e+00,\n",
       "        -1.06997810e-01,  8.52681696e-02, -5.78850619e-02,\n",
       "        -2.04261184e-01,  4.79274511e-01,  4.25967693e-01,\n",
       "         4.89592701e-01,  6.45972490e-02,  9.36417818e-01,\n",
       "        -1.03789702e-01,  2.91754961e-01,  2.14702815e-01,\n",
       "         1.14546978e+00, -1.26274064e-01, -1.09469116e-01,\n",
       "        -1.53060824e-01,  8.25477988e-02,  1.18365133e+00,\n",
       "         4.53053772e-01,  3.32951844e-01,  3.50214630e-01,\n",
       "        -5.60955070e-02,  2.17485622e-01,  7.65698552e-02,\n",
       "         3.36236060e-01,  1.02268410e+00, -2.21715663e-02,\n",
       "         7.53467977e-01,  1.54079556e+00,  4.36063409e-01,\n",
       "         5.72540574e-02, -1.32016055e-02,  4.02209818e-01,\n",
       "         1.37194812e-01,  1.80530339e-01,  4.90632027e-01,\n",
       "         1.25815308e+00,  3.71993542e-01,  4.97968823e-01,\n",
       "         5.63858002e-02, -1.68006271e-01,  7.09122479e-01,\n",
       "         5.01228750e-01,  3.49590570e-01,  1.33281720e+00,\n",
       "         5.17690837e-01, -1.52920699e-03, -7.90072680e-02,\n",
       "         9.99675691e-01, -8.45229477e-02, -2.28069481e-02,\n",
       "         1.60549843e+00, -1.25163704e-01,  4.65815008e-01,\n",
       "         7.01129884e-02,  7.55054727e-02,  3.30521256e-01,\n",
       "         1.28525926e-03,  5.03193498e-01,  3.56533080e-01,\n",
       "         6.94313586e-01,  5.94595075e-02,  1.14858615e+00,\n",
       "         1.41661954e+00,  1.09302990e-01,  2.61504292e-01,\n",
       "         3.44334021e-02,  1.59623548e-01,  3.96384269e-01,\n",
       "         1.24194197e-01,  5.08739650e-01,  9.59438920e-01,\n",
       "         1.10824466e+00,  2.44945899e-01,  4.24617261e-01,\n",
       "         9.94258165e-01,  4.99453396e-01,  3.27147335e-01,\n",
       "         2.68916905e-01, -7.32911229e-02, -1.56518474e-01,\n",
       "         2.86962271e-01,  5.47407627e-01,  2.30854601e-01,\n",
       "        -9.32041779e-02,  1.57348782e-01,  2.44830281e-01,\n",
       "         7.57100761e-01,  2.91341543e-01,  3.67603272e-01,\n",
       "         2.42773354e-01,  1.39929807e+00,  5.09549677e-01,\n",
       "         4.88199264e-01,  1.41333866e+00,  2.38421336e-01,\n",
       "        -1.55569673e-01,  1.79089832e+00, -1.70003653e-01,\n",
       "         9.02560115e-01,  2.14818552e-01,  8.51526082e-01,\n",
       "        -1.12864919e-01,  5.70605323e-02,  5.43948300e-02,\n",
       "         4.28076088e-01,  4.84201640e-01,  2.73016363e-01,\n",
       "        -6.71290830e-02,  9.66778100e-01, -1.40540481e-01,\n",
       "         3.47504377e-01,  9.49098408e-01,  8.65565091e-02,\n",
       "         8.71759713e-01,  4.63736504e-02, -1.19991533e-01,\n",
       "         3.99719141e-02, -1.15957141e-01,  8.22767019e-02,\n",
       "        -1.27094954e-01,  1.91161796e-01,  1.68249503e-01]], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exécution du modèle\n",
    "onnx_input = single_image_pipeline(\n",
    "    \"dataset/tomato/88614302-e6d2-4327-a4fb-a3db9c9ea72e___YLCV_NREC_2861.JPG\"\n",
    ")\n",
    "\n",
    "encoded_image = ort_session_encoder.run(None, {\"x\": onnx_input})[0]\n",
    "encoded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[8.7371554e-08, 9.9999952e-01, 3.8503146e-07]], dtype=float32)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decoding\n",
    "decoded_output = ort_session_decoder.run(None, {\"x\": encoded_image})\n",
    "decoded_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.7371e-08, 1.0000e+00, 3.8503e-07]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation avec pytorch\n",
    "torch_input = torch.tensor(onnx_input)\n",
    "encoded_image = inference_model_encoder(torch_input)\n",
    "decoded = inference_model_decoder(encoded_image)\n",
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
