{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compilation du modèle avec ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Préparation et compilation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Créé à l'aide de ChatGPT\n",
    "import torch\n",
    "\n",
    "class ReshapeToBatchChannelFirst(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReshapeToBatchChannelFirst, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Ensure the input is of shape (224, 224, 3)\n",
    "        #assert x.dim() == 3 and x.shape[-1] == 3, \"Input must be (224, 224, 3)\"\n",
    "        \n",
    "        # Permute dimensions from (H, W, C) to (C, H, W)\n",
    "        x = x.permute(2, 0, 1)\n",
    "        \n",
    "        # Add a batch dimension at the beginning: (1, C, H, W)\n",
    "        x = x.unsqueeze(0)\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "x = torch.rand(224, 224, 3)  # Example input\n",
    "layer = ReshapeToBatchChannelFirst()\n",
    "output = layer(x)\n",
    "print(output.shape)  # Expected: torch.Size([1, 3, 224, 224])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-2.4883]],\n",
      "\n",
      "         [[-2.4994]],\n",
      "\n",
      "         [[-2.4831]]]])\n"
     ]
    }
   ],
   "source": [
    "# Créé à l'aide de ChatGPT\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FixedNormLayer(torch.nn.Module):\n",
    "    def __init__(self, scale: torch.Tensor, mean: torch.Tensor, std: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            mean (torch.Tensor): Precomputed mean for normalization.\n",
    "            std (torch.Tensor): Precomputed standard deviation for normalization.\n",
    "        \"\"\"\n",
    "        super(FixedNormLayer, self).__init__()\n",
    "        self.register_buffer(\"mean\", mean[:, None, None])\n",
    "        self.register_buffer(\"std\", std[:, None, None])\n",
    "        self.register_buffer(\"scale\", scale)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return (self.scale * x - self.mean) / self.std\n",
    "\n",
    "# Example usage\n",
    "mean = torch.tensor([0.5, 0.5, 0.5])  # Example mean for 3 channels\n",
    "std = torch.tensor([0.2, 0.2, 0.2])   # Example std for 3 channels\n",
    "scale = torch.tensor([1 / 256])\n",
    "layer = FixedNormLayer(scale, mean, std)\n",
    "\n",
    "# Test with a sample input\n",
    "x = torch.rand(1, 3, 1, 1)  # Example input\n",
    "output = layer(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créé à l'aide de ChatGPT\n",
    "class InferenceModel(nn.Module):\n",
    "    def __init__(self, model, scale, mean, std):\n",
    "        super(InferenceModel, self).__init__()\n",
    "        self.preprocess = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\"reshape\", ReshapeToBatchChannelFirst()),\n",
    "                    (\"normalize\", FixedNormLayer(scale, mean, std)),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        self.model = model  # The main model\n",
    "        self.postprocess = torch.nn.Softmax(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.preprocess(x)  # Apply reshaping and normalization\n",
    "        x = self.model(x)  # Pass to the main model\n",
    "        return self.postprocess(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modification du modèle pour avoir le bon nombre de sortie dans la dernière couche et\n",
    "pour calculer le softmax sur les sorties du modèle pour avoir directement les probabilités."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained ViT\n",
    "num_labels = 11  # Get number of labels (e.g., 8)\n",
    "\n",
    "model = torchvision.models.vit_b_16(weights=\"IMAGENET1K_V1\")  # Load a pretrained model\n",
    "model.heads.head = torch.nn.Linear(model.heads.head.in_features, num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"models/tomato_model_2025_02_28_v2.pt\",\n",
    "        map_location=device,\n",
    "        weights_only=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0214, 0.6052, 0.2213, 0.0180, 0.0034, 0.0022, 0.0020, 0.0813, 0.0186,\n",
       "         0.0066, 0.0200]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create inference model\n",
    "scale = torch.tensor([1 / 256])\n",
    "mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "std = torch.tensor([0.229, 0.224, 0.225])\n",
    "inference_model = InferenceModel(model, scale, mean, std)\n",
    "inference_model.eval()\n",
    "\n",
    "test = torch.randn(224, 224, 3)\n",
    "inference_model(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exportation du modèle, en incluant un tenseur aléatoire pour fournir la bonne taille de\n",
    "tenseur en entrée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxime/.venvs/ai/lib64/python3.11/site-packages/torch/onnx/_internal/_exporter_legacy.py:116: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.\n",
      "  warnings.warn(\n",
      "/home/maxime/.venvs/ai/lib64/python3.11/site-packages/torch/onnx/_internal/fx/passes/readability.py:52: UserWarning: Attempted to insert a get_attr Node with no underlying reference in the owning GraphModule! Call GraphModule.add_submodule to add the necessary submodule, GraphModule.add_parameter to add the necessary Parameter, or nn.Module.register_buffer to add the necessary buffer\n",
      "  new_node = self.module.graph.get_attr(normalized_name)\n",
      "/home/maxime/.venvs/ai/lib64/python3.11/site-packages/torch/fx/graph.py:1586: UserWarning: Node preprocess_normalize_scale target preprocess/normalize/scale preprocess/normalize/scale of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "/home/maxime/.venvs/ai/lib64/python3.11/site-packages/torch/fx/graph.py:1586: UserWarning: Node preprocess_normalize_mean target preprocess/normalize/mean preprocess/normalize/mean of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "/home/maxime/.venvs/ai/lib64/python3.11/site-packages/torch/fx/graph.py:1586: UserWarning: Node preprocess_normalize_std target preprocess/normalize/std preprocess/normalize/std of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied 37 of general pattern rewrite rules.\n"
     ]
    }
   ],
   "source": [
    "torch_input = torch.randn(224, 224, 3)\n",
    "#onnx_program = torch.onnx.export(inference_model, torch_input, opset_version=14)\n",
    "onnx_program = torch.onnx.dynamo_export(inference_model, torch_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces warnings ne sont probablement pas grave, selon cette\n",
    "[source](https://github.com/pytorch/pytorch/issues/144331)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_program.save(\"models/tomato_model_2025_02_28_v2.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Validation de l'exécution du modèle avec ONNX runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(\n",
    "    \"models/tomato_model_2025_02_28_v2.onnx\", providers=[\"CPUExecutionProvider\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline fait sans pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_image_pipeline(image_path, dtype=\"float32\"):\n",
    "    # Load image into numpy float array\n",
    "    image = np.array(\n",
    "        PIL.Image.open(image_path).convert(\"RGB\").resize((224, 224)), dtype=dtype\n",
    "    )\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1.4499942e-06, 9.2473765e-06, 2.0949008e-06, 8.7807439e-06,\n",
       "         1.5942234e-05, 7.3268388e-06, 1.2185769e-06, 9.3832878e-06,\n",
       "         7.4934546e-06, 1.7394845e-05, 9.9991953e-01]], dtype=float32)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exécution du modèle\n",
    "onnx_input = single_image_pipeline(\n",
    "    \"dataset/tomato/88614302-e6d2-4327-a4fb-a3db9c9ea72e___YLCV_NREC_2861.JPG\"\n",
    ")\n",
    "\n",
    "onnxruntime_outputs = ort_session.run(None, {\"l_x_\": onnx_input})\n",
    "onnxruntime_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
